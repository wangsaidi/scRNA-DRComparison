{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "计算各方法的得分（综合相关指标），对应论文中的图3\n",
    "'''"
   ],
   "id": "e16d0aebb1800a85"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-15T14:05:01.806851Z",
     "start_time": "2025-09-15T14:05:01.801141Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 23,
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from functools import reduce"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 局部得分",
   "id": "df55f2395ee32d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T03:15:12.951246Z",
     "start_time": "2025-09-16T03:15:12.773190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "所有真实数据集：局部得分\n",
    "'''\n",
    "fragments = ['scDesign3','TI','SIMLR','VASC','benchmarker']\n",
    "all_dfs = []\n",
    "for fragment in fragments:\n",
    "    if fragment == 'scDesign3':\n",
    "        datasets = ['ACINAR','ATAC','BATCH','CITE','EMBYRO','MARROW','MOBSC','OVARIAN','PANCREAS','SCGEMMETH','SCGEMRNA','SCIATAC', 'VISIUM', 'IFNB','SLIDE']\n",
    "    elif fragment == 'TI':\n",
    "        datasets = ['DA1_horns','DC3_VA1d_horns','horns','blastocyst','epiblast','ICM','trophectoderm','combination-1','combination-2','combination-3','epidermis','muscle','neuron','pair-1','pair-2','pair-3','pair-4','parenchyme','phagocyte','pharynx']\n",
    "    elif fragment == 'SIMLR':\n",
    "        datasets = ['Pollen','Usoskin']\n",
    "    elif fragment == 'VASC':\n",
    "        datasets = ['Baron','Biase','Goolam','Xin','yan','Zeisel']\n",
    "    elif fragment == 'benchmarker':\n",
    "        datasets = ['Baron_mouse','Darmanis','Pancreatic','Silver','Zhengmix4eq']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        datapath1 = f'/home/henu/work/result/metric/{fragment}/{dataset}/dr1.csv'\n",
    "        datapath2 = f'/home/henu/work/result/metric/{fragment}/{dataset}/dr2.csv'\n",
    "        df1 = pd.read_csv(datapath1)\n",
    "        df2 = pd.read_csv(datapath2)\n",
    "        df_merge = pd.merge(df1, df2, on=\"Method\",how=\"outer\")\n",
    "\n",
    "        df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "        all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'random_triplet','spearman','k-nearest','centroid_distance','AUC','Qlocal','Qglobal','kmax']]\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/local.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "60dca5a5b49c8aea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  ACINAR   0.136   0.128   0.137  0.145   0.003   0.007   0.010   \n",
      "1   DREAM  ACINAR   0.127   0.135   0.128  0.136   0.003   0.007   0.010   \n",
      "2    EDGE  ACINAR   0.467   0.470   0.464  0.432   0.045   0.072   0.094   \n",
      "3  GLMPCA  ACINAR   0.577   0.590   0.594  0.588   0.064   0.094   0.117   \n",
      "4     PCA  ACINAR   0.475   0.497   0.490  0.499   0.069   0.105   0.131   \n",
      "\n",
      "   aji_10  ...    AUC  Qlocal  Qglobal   T_10   T_20   T_30   C_10   C_20  \\\n",
      "0   0.002  ...  0.502   0.326    0.827  0.504  0.503  0.504  0.502  0.502   \n",
      "1   0.002  ...  0.503   0.275    0.776  0.499  0.502  0.503  0.496  0.498   \n",
      "2   0.022  ...  0.556   0.233    0.607  0.797  0.792  0.789  0.682  0.676   \n",
      "3   0.032  ...  0.665   0.301    0.732  0.745  0.747  0.748  0.918  0.909   \n",
      "4   0.035  ...  0.658   0.317    0.716  0.754  0.754  0.754  0.912  0.904   \n",
      "\n",
      "    C_30  kmax  \n",
      "0  0.503  1974  \n",
      "1  0.500  1659  \n",
      "2  0.671   410  \n",
      "3  0.903   474  \n",
      "4  0.898   442  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.203268\n",
      "1               DREAM  0.444944\n",
      "2                EDGE  0.489279\n",
      "3              GLMPCA  0.531260\n",
      "4                 PCA  0.507457\n",
      "5               PHATE  0.568602\n",
      "6              PaCMAP  0.295416\n",
      "7   ParametricUMAP200  0.595152\n",
      "8    ParametricUMAP50  0.590510\n",
      "9              SAUCIE  0.442737\n",
      "10             SCDRHA  0.532000\n",
      "11              SIMLR  0.570173\n",
      "12               SPDR  0.609131\n",
      "13          SQuaD_MDS  0.539893\n",
      "14   SQuaD_MDS_hybrid  0.605140\n",
      "15             SSNMDI  0.275522\n",
      "16               TSNE  0.581460\n",
      "17             TriMap  0.603235\n",
      "18               UMAP  0.595787\n",
      "19                VAE  0.467402\n",
      "20               VASC  0.507565\n",
      "21               ZIFA  0.489012\n",
      "22               ivis  0.522776\n",
      "23               pCMF  0.386731\n",
      "24              scGAE  0.522075\n",
      "25              scGBM  0.541619\n",
      "26            scScope  0.441317\n",
      "27              scvis  0.607085\n",
      "28             tGPLVM  0.363931\n",
      "结果已保存到文件：/home/henu/work/result/score/local.csv\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 全局得分",
   "id": "62eeb6ef5d183a30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T03:16:16.941256Z",
     "start_time": "2025-09-16T03:16:16.739787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "所有真实数据集：全局得分\n",
    "'''\n",
    "fragments = ['scDesign3','TI','SIMLR','VASC','benchmarker']\n",
    "all_dfs = []\n",
    "for fragment in fragments:\n",
    "    if fragment == 'scDesign3':\n",
    "        datasets = ['ACINAR','ATAC','BATCH','CITE','EMBYRO','MARROW','MOBSC','OVARIAN','PANCREAS','SCGEMMETH','SCGEMRNA','SCIATAC', 'VISIUM', 'IFNB','SLIDE']\n",
    "    elif fragment == 'TI':\n",
    "        datasets = ['DA1_horns','DC3_VA1d_horns','horns','blastocyst','epiblast','ICM','trophectoderm','combination-1','combination-2','combination-3','epidermis','muscle','neuron','pair-1','pair-2','pair-3','pair-4','parenchyme','phagocyte','pharynx']\n",
    "    elif fragment == 'SIMLR':\n",
    "        datasets = ['Pollen','Usoskin']\n",
    "    elif fragment == 'VASC':\n",
    "        datasets = ['Baron','Biase','Goolam','Xin','yan','Zeisel']\n",
    "    elif fragment == 'benchmarker':\n",
    "        datasets = ['Baron_mouse','Darmanis','Pancreatic','Silver','Zhengmix4eq']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        datapath1 = f'/home/henu/work/result/metric/{fragment}/{dataset}/dr1.csv'\n",
    "        datapath2 = f'/home/henu/work/result/metric/{fragment}/{dataset}/dr2.csv'\n",
    "        df1 = pd.read_csv(datapath1)\n",
    "        df2 = pd.read_csv(datapath2)\n",
    "        df_merge = pd.merge(df1, df2, on=\"Method\",how=\"outer\")\n",
    "\n",
    "        df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "        all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'knn_10','knn_20','knn_30','svm','nkr_10','nkr_20','nkr_30','aji_10','aji_20','aji_30','AUC','Qlocal','Qglobal','kmax','T_10','T_20','T_30','C_10','C_20','C_30']]\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/global.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")\n"
   ],
   "id": "7b484d3731f0b8f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  ACINAR   0.136   0.128   0.137  0.145   0.003   0.007   0.010   \n",
      "1   DREAM  ACINAR   0.127   0.135   0.128  0.136   0.003   0.007   0.010   \n",
      "2    EDGE  ACINAR   0.467   0.470   0.464  0.432   0.045   0.072   0.094   \n",
      "3  GLMPCA  ACINAR   0.577   0.590   0.594  0.588   0.064   0.094   0.117   \n",
      "4     PCA  ACINAR   0.475   0.497   0.490  0.499   0.069   0.105   0.131   \n",
      "\n",
      "   aji_10  ...    AUC  Qlocal  Qglobal   T_10   T_20   T_30   C_10   C_20  \\\n",
      "0   0.002  ...  0.502   0.326    0.827  0.504  0.503  0.504  0.502  0.502   \n",
      "1   0.002  ...  0.503   0.275    0.776  0.499  0.502  0.503  0.496  0.498   \n",
      "2   0.022  ...  0.556   0.233    0.607  0.797  0.792  0.789  0.682  0.676   \n",
      "3   0.032  ...  0.665   0.301    0.732  0.745  0.747  0.748  0.918  0.909   \n",
      "4   0.035  ...  0.658   0.317    0.716  0.754  0.754  0.754  0.912  0.904   \n",
      "\n",
      "    C_30  kmax  \n",
      "0  0.503  1974  \n",
      "1  0.500  1659  \n",
      "2  0.671   410  \n",
      "3  0.903   474  \n",
      "4  0.898   442  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.301281\n",
      "1               DREAM  0.578288\n",
      "2                EDGE  0.518069\n",
      "3              GLMPCA  0.651950\n",
      "4                 PCA  0.702758\n",
      "5               PHATE  0.655408\n",
      "6              PaCMAP  0.366684\n",
      "7   ParametricUMAP200  0.644787\n",
      "8    ParametricUMAP50  0.653867\n",
      "9              SAUCIE  0.617468\n",
      "10             SCDRHA  0.691007\n",
      "11              SIMLR  0.568341\n",
      "12               SPDR  0.637689\n",
      "13          SQuaD_MDS  0.786424\n",
      "14   SQuaD_MDS_hybrid  0.702845\n",
      "15             SSNMDI  0.324199\n",
      "16               TSNE  0.597026\n",
      "17             TriMap  0.699466\n",
      "18               UMAP  0.631457\n",
      "19                VAE  0.505549\n",
      "20               VASC  0.636711\n",
      "21               ZIFA  0.640172\n",
      "22               ivis  0.620318\n",
      "23               pCMF  0.545297\n",
      "24              scGAE  0.582868\n",
      "25              scGBM  0.671931\n",
      "26            scScope  0.557511\n",
      "27              scvis  0.735317\n",
      "28             tGPLVM  0.547550\n",
      "结果已保存到文件：/home/henu/work/result/score/global.csv\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 聚类得分",
   "id": "cf56ecdbd9ca421c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T03:17:19.405519Z",
     "start_time": "2025-09-16T03:17:19.011468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "所有真实数据集：聚类得分\n",
    "kmeans\n",
    "'''\n",
    "fragments = ['scDesign3','TI','SIMLR','VASC','benchmarker']\n",
    "all_dfs = []\n",
    "cluster_method = 'kmeans'\n",
    "for fragment in fragments:\n",
    "    if fragment == 'scDesign3':\n",
    "        datasets = ['ACINAR','ATAC','BATCH','CITE','EMBYRO','MARROW','MOBSC','OVARIAN','PANCREAS','SCGEMMETH','SCGEMRNA','SCIATAC', 'VISIUM', 'IFNB','SLIDE']\n",
    "    elif fragment == 'TI':\n",
    "        datasets = ['DA1_horns','DC3_VA1d_horns','horns','blastocyst','epiblast','ICM','trophectoderm','combination-1','combination-2','combination-3','epidermis','muscle','neuron','pair-1','pair-2','pair-3','pair-4','parenchyme','phagocyte','pharynx']\n",
    "    elif fragment == 'SIMLR':\n",
    "        datasets = ['Pollen','Usoskin']\n",
    "    elif fragment == 'VASC':\n",
    "        datasets = ['Baron','Biase','Goolam','Xin','yan','Zeisel']\n",
    "    elif fragment == 'benchmarker':\n",
    "        datasets = ['Baron_mouse','Darmanis','Pancreatic','Silver','Zhengmix4eq']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        datapath1 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_ARI.csv'\n",
    "        datapath2 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_NMI.csv'\n",
    "        datapath3 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_SIL.csv'\n",
    "        datapath4 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_COMP.csv'\n",
    "        datapath5 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_HOMO.csv'\n",
    "        df1 = pd.read_csv(datapath1)\n",
    "        df2 = pd.read_csv(datapath2)\n",
    "        df3 = pd.read_csv(datapath3)\n",
    "        df4 = pd.read_csv(datapath4)\n",
    "        df5 = pd.read_csv(datapath5)\n",
    "        df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5])\n",
    "\n",
    "        df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "        all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\"]]\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/kmeans.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")\n"
   ],
   "id": "f2aaf7e7476421f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method Dataset   ARI   NMI   SIL  COMP  HOMO\n",
      "0     DRA  ACINAR  0.00  0.01  0.35  0.01  0.01\n",
      "1   DREAM  ACINAR  0.00  0.01  0.32  0.01  0.01\n",
      "2    EDGE  ACINAR  0.14  0.23  0.56  0.23  0.23\n",
      "3  GLMPCA  ACINAR  0.29  0.45  0.36  0.45  0.44\n",
      "4     PCA  ACINAR  0.15  0.31  0.35  0.32  0.30\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.162800\n",
      "1               DREAM  0.462572\n",
      "2                EDGE  0.486485\n",
      "3              GLMPCA  0.608917\n",
      "4                 PCA  0.549690\n",
      "5               PHATE  0.602700\n",
      "6              PaCMAP  0.306871\n",
      "7   ParametricUMAP200  0.590043\n",
      "8    ParametricUMAP50  0.589401\n",
      "9              SAUCIE  0.356084\n",
      "10             SCDRHA  0.518872\n",
      "11              SIMLR  0.611821\n",
      "12               SPDR  0.605149\n",
      "13          SQuaD_MDS  0.453330\n",
      "14   SQuaD_MDS_hybrid  0.534743\n",
      "15             SSNMDI  0.266731\n",
      "16               TSNE  0.606920\n",
      "17             TriMap  0.613567\n",
      "18               UMAP  0.578703\n",
      "19                VAE  0.460403\n",
      "20               VASC  0.596405\n",
      "21               ZIFA  0.548819\n",
      "22               ivis  0.548519\n",
      "23               pCMF  0.317664\n",
      "24              scGAE  0.482754\n",
      "25              scGBM  0.619152\n",
      "26            scScope  0.365586\n",
      "27              scvis  0.583941\n",
      "28             tGPLVM  0.339313\n",
      "结果已保存到文件：/home/henu/work/result/score/kmeans.csv\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T03:17:55.282262Z",
     "start_time": "2025-09-16T03:17:54.873836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "所有真实数据集：聚类得分\n",
    "louvain\n",
    "'''\n",
    "fragments = ['scDesign3','TI','SIMLR','VASC','benchmarker']\n",
    "all_dfs = []\n",
    "cluster_method = 'louvain'\n",
    "for fragment in fragments:\n",
    "    if fragment == 'scDesign3':\n",
    "        datasets = ['ACINAR','ATAC','BATCH','CITE','EMBYRO','MARROW','MOBSC','OVARIAN','PANCREAS','SCGEMMETH','SCGEMRNA','SCIATAC', 'VISIUM', 'IFNB','SLIDE']\n",
    "    elif fragment == 'TI':\n",
    "        datasets = ['DA1_horns','DC3_VA1d_horns','horns','blastocyst','epiblast','ICM','trophectoderm','combination-1','combination-2','combination-3','epidermis','muscle','neuron','pair-1','pair-2','pair-3','pair-4','parenchyme','phagocyte','pharynx']\n",
    "    elif fragment == 'SIMLR':\n",
    "        datasets = ['Pollen','Usoskin']\n",
    "    elif fragment == 'VASC':\n",
    "        datasets = ['Baron','Biase','Goolam','Xin','yan','Zeisel']\n",
    "    elif fragment == 'benchmarker':\n",
    "        datasets = ['Baron_mouse','Darmanis','Pancreatic','Silver','Zhengmix4eq']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        datapath1 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_ARI.csv'\n",
    "        datapath2 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_NMI.csv'\n",
    "        datapath3 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_SIL.csv'\n",
    "        datapath4 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_COMP.csv'\n",
    "        datapath5 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_HOMO.csv'\n",
    "        df1 = pd.read_csv(datapath1)\n",
    "        df2 = pd.read_csv(datapath2)\n",
    "        df3 = pd.read_csv(datapath3)\n",
    "        df4 = pd.read_csv(datapath4)\n",
    "        df5 = pd.read_csv(datapath5)\n",
    "        df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5])\n",
    "\n",
    "        df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "        all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\"]]\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/louvain.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")\n"
   ],
   "id": "9efc16e434e3b846",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method Dataset   ARI   NMI   SIL  COMP  HOMO\n",
      "0     DRA  ACINAR  0.00  0.02  0.24  0.02  0.03\n",
      "1   DREAM  ACINAR  0.00  0.02  0.19  0.02  0.03\n",
      "2    EDGE  ACINAR  0.07  0.25  0.45  0.20  0.33\n",
      "3  GLMPCA  ACINAR  0.14  0.39  0.24  0.32  0.51\n",
      "4     PCA  ACINAR  0.10  0.33  0.26  0.26  0.43\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.148193\n",
      "1               DREAM  0.409723\n",
      "2                EDGE  0.455139\n",
      "3              GLMPCA  0.495079\n",
      "4                 PCA  0.462134\n",
      "5               PHATE  0.492252\n",
      "6              PaCMAP  0.286589\n",
      "7   ParametricUMAP200  0.501074\n",
      "8    ParametricUMAP50  0.495374\n",
      "9              SAUCIE  0.333851\n",
      "10             SCDRHA  0.458110\n",
      "11              SIMLR  0.534594\n",
      "12               SPDR  0.509282\n",
      "13          SQuaD_MDS  0.424490\n",
      "14   SQuaD_MDS_hybrid  0.482759\n",
      "15             SSNMDI  0.271789\n",
      "16               TSNE  0.539034\n",
      "17             TriMap  0.520652\n",
      "18               UMAP  0.499921\n",
      "19                VAE  0.415271\n",
      "20               VASC  0.480352\n",
      "21               ZIFA  0.468830\n",
      "22               ivis  0.473290\n",
      "23               pCMF  0.306472\n",
      "24              scGAE  0.477282\n",
      "25              scGBM  0.511222\n",
      "26            scScope  0.341728\n",
      "27              scvis  0.490823\n",
      "28             tGPLVM  0.296361\n",
      "结果已保存到文件：/home/henu/work/result/score/louvain.csv\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T03:18:10.342061Z",
     "start_time": "2025-09-16T03:18:09.921949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "所有真实数据集：聚类得分\n",
    "spectral\n",
    "'''\n",
    "fragments = ['scDesign3','TI','SIMLR','VASC','benchmarker']\n",
    "all_dfs = []\n",
    "cluster_method = 'spectral'\n",
    "for fragment in fragments:\n",
    "    if fragment == 'scDesign3':\n",
    "        datasets = ['ACINAR','ATAC','BATCH','CITE','EMBYRO','MARROW','MOBSC','OVARIAN','PANCREAS','SCGEMMETH','SCGEMRNA','SCIATAC', 'VISIUM', 'IFNB','SLIDE']\n",
    "    elif fragment == 'TI':\n",
    "        datasets = ['DA1_horns','DC3_VA1d_horns','horns','blastocyst','epiblast','ICM','trophectoderm','combination-1','combination-2','combination-3','epidermis','muscle','neuron','pair-1','pair-2','pair-3','pair-4','parenchyme','phagocyte','pharynx']\n",
    "    elif fragment == 'SIMLR':\n",
    "        datasets = ['Pollen','Usoskin']\n",
    "    elif fragment == 'VASC':\n",
    "        datasets = ['Baron','Biase','Goolam','Xin','yan','Zeisel']\n",
    "    elif fragment == 'benchmarker':\n",
    "        datasets = ['Baron_mouse','Darmanis','Pancreatic','Silver','Zhengmix4eq']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        datapath1 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_ARI.csv'\n",
    "        datapath2 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_NMI.csv'\n",
    "        datapath3 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_SIL.csv'\n",
    "        datapath4 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_COMP.csv'\n",
    "        datapath5 = f'/home/henu/work/result/cluster/{fragment}/{dataset}/indicators/{cluster_method}_HOMO.csv'\n",
    "        df1 = pd.read_csv(datapath1)\n",
    "        df2 = pd.read_csv(datapath2)\n",
    "        df3 = pd.read_csv(datapath3)\n",
    "        df4 = pd.read_csv(datapath4)\n",
    "        df5 = pd.read_csv(datapath5)\n",
    "        df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5])\n",
    "\n",
    "        df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "        all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\"]]\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/spectral.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")\n"
   ],
   "id": "2c10a6ae0f72809b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method Dataset   ARI   NMI   SIL  COMP  HOMO\n",
      "0     DRA  ACINAR  0.00  0.01  0.31  0.01  0.01\n",
      "1   DREAM  ACINAR  0.00  0.01  0.26  0.01  0.01\n",
      "2    EDGE  ACINAR  0.09  0.19  0.08  0.19  0.19\n",
      "3  GLMPCA  ACINAR  0.30  0.46  0.31  0.46  0.47\n",
      "4     PCA  ACINAR  0.17  0.32  0.30  0.32  0.33\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.163091\n",
      "1               DREAM  0.468047\n",
      "2                EDGE  0.482877\n",
      "3              GLMPCA  0.596221\n",
      "4                 PCA  0.523026\n",
      "5               PHATE  0.577397\n",
      "6              PaCMAP  0.298294\n",
      "7   ParametricUMAP200  0.584175\n",
      "8    ParametricUMAP50  0.583729\n",
      "9              SAUCIE  0.365688\n",
      "10             SCDRHA  0.492569\n",
      "11              SIMLR  0.576569\n",
      "12               SPDR  0.590062\n",
      "13          SQuaD_MDS  0.464530\n",
      "14   SQuaD_MDS_hybrid  0.546764\n",
      "15             SSNMDI  0.242744\n",
      "16               TSNE  0.627409\n",
      "17             TriMap  0.607036\n",
      "18               UMAP  0.582215\n",
      "19                VAE  0.473684\n",
      "20               VASC  0.556063\n",
      "21               ZIFA  0.541616\n",
      "22               ivis  0.562413\n",
      "23               pCMF  0.324140\n",
      "24              scGAE  0.506410\n",
      "25              scGBM  0.609836\n",
      "26            scScope  0.378899\n",
      "27              scvis  0.583473\n",
      "28             tGPLVM  0.330942\n",
      "结果已保存到文件：/home/henu/work/result/score/spectral.csv\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 时间与内存得分",
   "id": "46784cb4d7299bc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T09:27:49.442958Z",
     "start_time": "2025-09-16T09:27:49.440641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "时间与内存得分的计算是按数据集进行归一化的，不是整合所有数据集之后，整体按列进行归一化的；\n",
    "单个数据集归一化，计算方法在这个数据集上的得分，取所有数据集上得分的均值作为该方法最终得分；1-x，得分符合折线图；\n",
    "'''"
   ],
   "id": "1b4032c040b29b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T09:25:40.375514Z",
     "start_time": "2025-09-16T09:25:40.302835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "时间\n",
    "'''\n",
    "# 所有数据集的列表\n",
    "datasets = ['cell_100','cell_500','cell_1000','cell_2000','cell_5000','cell_10000','cell_20000','cell_30000','cell_50000','cell_73233']\n",
    "all_dfs = []\n",
    "\n",
    "# 读取所有数据集\n",
    "for dataset in datasets:\n",
    "    datapath = f'/home/henu/work/result/efficiency/{dataset}.csv'\n",
    "    df = pd.read_csv(datapath)\n",
    "\n",
    "    df.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\", 'PeakMemory(gb)']]\n",
    "\n",
    "# -------- Step 1: 按每个数据集标准化（Min-Max 归一化） --------\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 用于存储标准化后的数据\n",
    "df_all_normalized = df_all.copy()\n",
    "\n",
    "for dataset in datasets:\n",
    "    # 按每个数据集进行标准化\n",
    "    df_dataset = df_all[df_all[\"Dataset\"] == dataset]\n",
    "\n",
    "    # 对指标列进行标准化\n",
    "    df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
    "\n",
    "    # 将标准化后的数据合并回原始数据\n",
    "    df_all_normalized.update(df_dataset)\n",
    "\n",
    "# -------- Step 2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all_normalized[\"Accuracy_subscore\"] = df_all_normalized[metric_cols].mean(axis=1)\n",
    "\n",
    "# -------- Step 3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all_normalized.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "# 计算得分时取反（高分表示低成本）\n",
    "accuracy_scores['score'] = 1 - accuracy_scores['score']\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/time.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "14ce2460efea8d25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "      Method   Dataset  PeakMemory(gb)  Time(s)\n",
      "0     SAUCIE  cell_100           0.289   1.2138\n",
      "1  SQuaD-MDS  cell_100           0.260   2.6305\n",
      "2       UMAP  cell_100           0.722   7.3263\n",
      "3     SCDRHA  cell_100           0.626  13.4948\n",
      "4      scGAE  cell_100           0.514   3.3701\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "       Method     score\n",
      "0         DRA  0.826749\n",
      "1       DREAM  0.893422\n",
      "2        EDGE  0.864895\n",
      "3      GLMPCA  0.984293\n",
      "4         PCA  0.999858\n",
      "5       PHATE  0.993161\n",
      "6      PaCMAP  0.996160\n",
      "7      SAUCIE  0.999238\n",
      "8      SCDRHA  0.904575\n",
      "9       SIMLR  0.662293\n",
      "10       SPDR  0.810968\n",
      "11  SQuaD-MDS  0.980002\n",
      "12     SSNMDI  0.721061\n",
      "13     TriMap  0.998207\n",
      "14       UMAP  0.993611\n",
      "15        VAE  0.947520\n",
      "16       VASC  0.406081\n",
      "17       ZIFA  0.765998\n",
      "18       ivis  0.993506\n",
      "19       pCMF  0.502604\n",
      "20      scGAE  0.917079\n",
      "21      scGBM  0.988004\n",
      "22    scScope  0.952114\n",
      "23      scvis  0.361316\n",
      "24      t-SNE  0.992975\n",
      "25     tGPLVM  0.910891\n",
      "结果已保存到文件：/home/henu/work/result/score/time.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/2302181881.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T09:20:56.125287Z",
     "start_time": "2025-09-16T09:20:56.046319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "内存\n",
    "'''\n",
    "# 所有数据集的列表\n",
    "datasets = ['cell_100','cell_500','cell_1000','cell_2000','cell_5000','cell_10000','cell_20000','cell_30000','cell_50000','cell_73233']\n",
    "all_dfs = []\n",
    "\n",
    "# 读取所有数据集\n",
    "for dataset in datasets:\n",
    "    datapath = f'/home/henu/work/result/efficiency/{dataset}.csv'\n",
    "    df = pd.read_csv(datapath)\n",
    "\n",
    "    df.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\", 'Time(s)']]\n",
    "\n",
    "# -------- Step 1: 按每个数据集标准化（Min-Max 归一化） --------\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 用于存储标准化后的数据\n",
    "df_all_normalized = df_all.copy()\n",
    "\n",
    "for dataset in datasets:\n",
    "    # 按每个数据集进行标准化\n",
    "    df_dataset = df_all[df_all[\"Dataset\"] == dataset]\n",
    "\n",
    "    # 对指标列进行标准化\n",
    "    df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
    "\n",
    "    # 将标准化后的数据合并回原始数据\n",
    "    df_all_normalized.update(df_dataset)\n",
    "\n",
    "# -------- Step 2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all_normalized[\"Accuracy_subscore\"] = df_all_normalized[metric_cols].mean(axis=1)\n",
    "\n",
    "# -------- Step 3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all_normalized.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "# 计算得分时取反（高分表示低成本）\n",
    "accuracy_scores['score'] = 1 - accuracy_scores['score']\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/memory.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "3c30664e15f46e86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "      Method   Dataset  PeakMemory(gb)  Time(s)\n",
      "0     SAUCIE  cell_100           0.289   1.2138\n",
      "1  SQuaD-MDS  cell_100           0.260   2.6305\n",
      "2       UMAP  cell_100           0.722   7.3263\n",
      "3     SCDRHA  cell_100           0.626  13.4948\n",
      "4      scGAE  cell_100           0.514   3.3701\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "       Method     score\n",
      "0         DRA  0.959883\n",
      "1       DREAM  0.794299\n",
      "2        EDGE  0.398328\n",
      "3      GLMPCA  0.974607\n",
      "4         PCA  0.991381\n",
      "5       PHATE  0.980804\n",
      "6      PaCMAP  0.977187\n",
      "7      SAUCIE  0.975789\n",
      "8      SCDRHA  0.506289\n",
      "9       SIMLR  0.367526\n",
      "10       SPDR  0.938520\n",
      "11  SQuaD-MDS  0.976456\n",
      "12     SSNMDI  0.740276\n",
      "13     TriMap  0.976543\n",
      "14       UMAP  0.906186\n",
      "15        VAE  0.927733\n",
      "16       VASC  0.955671\n",
      "17       ZIFA  0.933574\n",
      "18       ivis  0.929538\n",
      "19       pCMF  0.973060\n",
      "20      scGAE  0.666807\n",
      "21      scGBM  0.954582\n",
      "22    scScope  0.913354\n",
      "23      scvis  0.973818\n",
      "24      t-SNE  0.991186\n",
      "25     tGPLVM  0.936219\n",
      "结果已保存到文件：/home/henu/work/result/score/memory.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n",
      "/tmp/ipykernel_683846/3974064057.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset[metric_cols] = scaler.fit_transform(df_dataset[metric_cols])\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 稳定性得分",
   "id": "25f2b8e1016348f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T03:41:31.023832Z",
     "start_time": "2025-09-16T03:41:30.900143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "细胞数量稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['cell_100','cell_500','cell_1k','cell_5k','cell_1w','cell_2w','cell_3w']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/cell_number.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "c5ad11f2d904adcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method   Dataset  knn_10  knn_20  knn_30   svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  cell_100    0.19    0.28    0.26  0.24   0.082   0.187   0.279   \n",
      "1   DREAM  cell_100    0.39    0.39    0.43  0.36   0.138   0.297   0.435   \n",
      "2    EDGE  cell_100    0.42    0.46    0.47  0.46   0.128   0.242   0.342   \n",
      "3  GLMPCA  cell_100    0.72    0.74    0.73  0.74   0.148   0.328   0.447   \n",
      "4     PCA  cell_100    0.83    0.89    0.87  0.88   0.150   0.312   0.403   \n",
      "\n",
      "   aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  COMP  HOMO  \n",
      "0   0.045  ...  0.532  0.523  0.506  0.504     2  0.01  0.06  0.38  0.06  0.05  \n",
      "1   0.083  ...  0.709  0.721  0.731  0.750    39  0.06  0.14  0.38  0.16  0.12  \n",
      "2   0.070  ...  0.606  0.575  0.594  0.601    53  0.05  0.14  0.32  0.14  0.14  \n",
      "3   0.085  ...  0.705  0.722  0.748  0.762    33  0.45  0.55  0.38  0.56  0.55  \n",
      "4   0.089  ...  0.662  0.690  0.717  0.734    44  0.81  0.89  0.61  0.91  0.87  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.153538\n",
      "1               DREAM  0.366476\n",
      "2                EDGE  0.546420\n",
      "3              GLMPCA  0.560411\n",
      "4                 PCA  0.603821\n",
      "5               PHATE  0.631224\n",
      "6              PaCMAP  0.179524\n",
      "7   ParametricUMAP200  0.618136\n",
      "8    ParametricUMAP50  0.616267\n",
      "9              SAUCIE  0.143944\n",
      "10             SCDRHA  0.402840\n",
      "11              SIMLR  0.636787\n",
      "12               SPDR  0.646036\n",
      "13          SQuaD_MDS  0.449090\n",
      "14   SQuaD_MDS_hybrid  0.572334\n",
      "15             SSNMDI  0.152537\n",
      "16               TSNE  0.645067\n",
      "17             TriMap  0.671673\n",
      "18               UMAP  0.595648\n",
      "19                VAE  0.555822\n",
      "20               ZIFA  0.596847\n",
      "21               ivis  0.450271\n",
      "22               pCMF  0.141178\n",
      "23              scGAE  0.197426\n",
      "24              scGBM  0.576974\n",
      "25            scScope  0.396154\n",
      "26              scvis  0.185085\n",
      "27             tGPLVM  0.530008\n",
      "结果已保存到文件：/home/henu/work/result/score/cell_number.csv\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T03:53:45.141589Z",
     "start_time": "2025-09-16T03:53:45.026093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "基因数量稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['gene_5k','gene_2w','gene_3w','gene_4w','gene_5w']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/gene_number.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "261d24d5b803081c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method  Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  gene_5k   0.230   0.248   0.270  0.301   0.004   0.010   0.015   \n",
      "1   DREAM  gene_5k   0.266   0.276   0.281  0.308   0.005   0.011   0.016   \n",
      "2    EDGE  gene_5k   0.932   0.934   0.934  0.932   0.016   0.031   0.045   \n",
      "3  GLMPCA  gene_5k   0.974   0.973   0.973  0.974   0.016   0.031   0.045   \n",
      "4     PCA  gene_5k   0.927   0.928   0.928  0.935   0.016   0.029   0.042   \n",
      "\n",
      "   aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  COMP  HOMO  \n",
      "0   0.002  ...  0.504  0.501  0.510  0.514   360 -0.00  0.00  0.32  0.00  0.00  \n",
      "1   0.003  ...  0.506  0.566  0.555  0.549  1276  0.00  0.01  0.32  0.01  0.01  \n",
      "2   0.009  ...  0.618  0.766  0.746  0.730   385  0.78  0.75  0.41  0.74  0.76  \n",
      "3   0.008  ...  0.639  0.784  0.766  0.754   398  0.95  0.92  0.57  0.91  0.92  \n",
      "4   0.008  ...  0.627  0.774  0.755  0.742   394  0.93  0.91  0.71  0.91  0.91  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.126835\n",
      "1               DREAM  0.315962\n",
      "2                EDGE  0.706817\n",
      "3              GLMPCA  0.684525\n",
      "4                 PCA  0.700176\n",
      "5               PHATE  0.784143\n",
      "6              PaCMAP  0.126713\n",
      "7   ParametricUMAP200  0.799990\n",
      "8    ParametricUMAP50  0.790719\n",
      "9              SAUCIE  0.112097\n",
      "10             SCDRHA  0.606476\n",
      "11              SIMLR  0.837006\n",
      "12               SPDR  0.818976\n",
      "13          SQuaD_MDS  0.469207\n",
      "14   SQuaD_MDS_hybrid  0.747514\n",
      "15             SSNMDI  0.115790\n",
      "16               TSNE  0.795337\n",
      "17             TriMap  0.851233\n",
      "18               UMAP  0.793596\n",
      "19                VAE  0.780726\n",
      "20               ZIFA  0.690868\n",
      "21               ivis  0.564478\n",
      "22               pCMF  0.097991\n",
      "23              scGAE  0.351080\n",
      "24              scGBM  0.666859\n",
      "25            scScope  0.407131\n",
      "26              scvis  0.144490\n",
      "27             tGPLVM  0.663492\n",
      "结果已保存到文件：/home/henu/work/result/score/gene_number.csv\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T03:55:55.506895Z",
     "start_time": "2025-09-16T03:55:55.404808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "类型数量稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['celltype_7','celltype_9','celltype_11','celltype_13','celltype_15']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/celltype_number.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "c3898d4a64df808d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method     Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  celltype_7   0.158   0.159   0.150  0.128   0.005   0.011   0.016   \n",
      "1   DREAM  celltype_7   0.136   0.143   0.150  0.176   0.005   0.010   0.015   \n",
      "2    EDGE  celltype_7   0.731   0.731   0.730  0.736   0.016   0.029   0.041   \n",
      "3  GLMPCA  celltype_7   0.713   0.727   0.728  0.742   0.017   0.030   0.041   \n",
      "4     PCA  celltype_7   0.828   0.834   0.837  0.841   0.018   0.033   0.045   \n",
      "\n",
      "   aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  COMP  HOMO  \n",
      "0   0.003  ...  0.504  0.537  0.530  0.527   422 -0.00  0.00  0.33  0.00  0.00  \n",
      "1   0.002  ...  0.505  0.478  0.489  0.496   659  0.00  0.01  0.32  0.01  0.01  \n",
      "2   0.009  ...  0.593  0.706  0.679  0.664   285  0.53  0.53  0.39  0.53  0.53  \n",
      "3   0.009  ...  0.606  0.740  0.716  0.702   316  0.55  0.65  0.39  0.65  0.65  \n",
      "4   0.009  ...  0.620  0.701  0.677  0.665   285  0.73  0.78  0.55  0.78  0.78  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.189703\n",
      "1               DREAM  0.182871\n",
      "2                EDGE  0.433824\n",
      "3              GLMPCA  0.502622\n",
      "4                 PCA  0.521842\n",
      "5               PHATE  0.778916\n",
      "6              PaCMAP  0.197544\n",
      "7   ParametricUMAP200  0.723841\n",
      "8    ParametricUMAP50  0.703705\n",
      "9              SAUCIE  0.131106\n",
      "10             SCDRHA  0.524916\n",
      "11              SIMLR  0.791543\n",
      "12               SPDR  0.845381\n",
      "13          SQuaD_MDS  0.427870\n",
      "14   SQuaD_MDS_hybrid  0.574079\n",
      "15             SSNMDI  0.180423\n",
      "16               TSNE  0.841931\n",
      "17             TriMap  0.860045\n",
      "18               UMAP  0.676470\n",
      "19                VAE  0.796553\n",
      "20               ZIFA  0.463674\n",
      "21               ivis  0.225123\n",
      "22               pCMF  0.159384\n",
      "23              scGAE  0.153953\n",
      "24              scGBM  0.484445\n",
      "25            scScope  0.186398\n",
      "26              scvis  0.183200\n",
      "27             tGPLVM  0.187043\n",
      "结果已保存到文件：/home/henu/work/result/score/celltype_number.csv\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:34:28.009498Z",
     "start_time": "2025-09-16T06:34:27.910729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "批次数量稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['batch_2','batch_4','batch_6','batch_8','batch_10']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/batch_number.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "b97d62fcd63da47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method  Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  batch_2   0.256   0.252   0.256  0.290   0.005   0.010   0.015   \n",
      "1   DREAM  batch_2   0.459   0.490   0.485  0.508   0.008   0.015   0.023   \n",
      "2    EDGE  batch_2   0.965   0.967   0.967  0.964   0.025   0.042   0.060   \n",
      "3  GLMPCA  batch_2   0.739   0.756   0.760  0.765   0.020   0.036   0.050   \n",
      "4     PCA  batch_2   0.760   0.776   0.773  0.769   0.020   0.035   0.049   \n",
      "\n",
      "   aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  COMP  HOMO  \n",
      "0   0.003  ...  0.505  0.516  0.510  0.508  1502 -0.00  0.00  0.33  0.00  0.00  \n",
      "1   0.004  ...  0.539  0.567  0.572  0.574   524  0.11  0.15  0.31  0.15  0.15  \n",
      "2   0.013  ...  0.677  0.783  0.763  0.751   385  0.85  0.81  0.49  0.80  0.82  \n",
      "3   0.010  ...  0.653  0.763  0.754  0.749   399  0.48  0.58  0.62  0.58  0.57  \n",
      "4   0.010  ...  0.655  0.769  0.759  0.753   386  0.51  0.63  0.77  0.63  0.63  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.122800\n",
      "1               DREAM  0.234661\n",
      "2                EDGE  0.604743\n",
      "3              GLMPCA  0.582238\n",
      "4                 PCA  0.623062\n",
      "5               PHATE  0.750944\n",
      "6              PaCMAP  0.161242\n",
      "7   ParametricUMAP200  0.731852\n",
      "8    ParametricUMAP50  0.722646\n",
      "9              SAUCIE  0.096773\n",
      "10             SCDRHA  0.568441\n",
      "11              SIMLR  0.734442\n",
      "12               SPDR  0.828187\n",
      "13          SQuaD_MDS  0.438938\n",
      "14   SQuaD_MDS_hybrid  0.630782\n",
      "15             SSNMDI  0.123891\n",
      "16               TSNE  0.812751\n",
      "17             TriMap  0.831851\n",
      "18               UMAP  0.711459\n",
      "19                VAE  0.699879\n",
      "20               ZIFA  0.616412\n",
      "21               ivis  0.414799\n",
      "22               pCMF  0.084158\n",
      "23              scGAE  0.186110\n",
      "24              scGBM  0.597721\n",
      "25            scScope  0.121182\n",
      "26              scvis  0.151812\n",
      "27             tGPLVM  0.632423\n",
      "结果已保存到文件：/home/henu/work/result/score/batch_number.csv\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:36:29.074963Z",
     "start_time": "2025-09-16T06:36:28.965636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "批次强度稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['batch_0.2','batch_0.4','batch_0.6','batch_0.8','batch_1.0']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/batch_strength.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "c158bdc64c666402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method    Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  batch_0.2   0.244   0.270   0.282  0.298   0.005   0.010   0.015   \n",
      "1   DREAM  batch_0.2   0.306   0.348   0.369  0.376   0.011   0.022   0.033   \n",
      "2    EDGE  batch_0.2   0.901   0.901   0.900  0.847   0.033   0.058   0.080   \n",
      "3  GLMPCA  batch_0.2   0.735   0.742   0.746  0.751   0.024   0.047   0.068   \n",
      "4     PCA  batch_0.2   0.751   0.755   0.764  0.773   0.026   0.048   0.068   \n",
      "\n",
      "   aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  COMP  HOMO  \n",
      "0   0.003  ...  0.505  0.501  0.505  0.506  1669  0.00  0.00  0.32  0.00  0.00  \n",
      "1   0.005  ...  0.738  0.758  0.757  0.757   870  0.02  0.03  0.35  0.03  0.03  \n",
      "2   0.017  ...  0.809  0.875  0.861  0.854   951  0.29  0.39  0.45  0.38  0.39  \n",
      "3   0.013  ...  0.800  0.875  0.867  0.861   920  0.33  0.51  0.64  0.51  0.51  \n",
      "4   0.013  ...  0.799  0.877  0.868  0.862   934  0.34  0.55  0.73  0.55  0.55  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.082157\n",
      "1               DREAM  0.351878\n",
      "2                EDGE  0.634031\n",
      "3              GLMPCA  0.437142\n",
      "4                 PCA  0.648394\n",
      "5               PHATE  0.775832\n",
      "6              PaCMAP  0.207314\n",
      "7   ParametricUMAP200  0.782397\n",
      "8    ParametricUMAP50  0.779649\n",
      "9              SAUCIE  0.253454\n",
      "10             SCDRHA  0.580844\n",
      "11              SIMLR  0.833488\n",
      "12               SPDR  0.826467\n",
      "13          SQuaD_MDS  0.458814\n",
      "14   SQuaD_MDS_hybrid  0.706870\n",
      "15             SSNMDI  0.198512\n",
      "16               TSNE  0.784855\n",
      "17             TriMap  0.809477\n",
      "18               UMAP  0.760670\n",
      "19                VAE  0.738208\n",
      "20               ZIFA  0.622363\n",
      "21               ivis  0.421375\n",
      "22               pCMF  0.296417\n",
      "23              scGAE  0.291280\n",
      "24              scGBM  0.629440\n",
      "25            scScope  0.331259\n",
      "26              scvis  0.518507\n",
      "27             tGPLVM  0.448599\n",
      "结果已保存到文件：/home/henu/work/result/score/batch_strength.csv\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:37:41.466027Z",
     "start_time": "2025-09-16T06:37:41.359876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "dropout稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['dropout_-1','dropout_0','dropout_1','dropout_2','dropout_3']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/dropout.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "fa247868e7572519",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method     Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  dropout_-1   0.232   0.256   0.256  0.290   0.005   0.010   0.015   \n",
      "1   DREAM  dropout_-1   0.332   0.370   0.376  0.398   0.006   0.012   0.018   \n",
      "2    EDGE  dropout_-1   0.956   0.959   0.960  0.960   0.020   0.036   0.051   \n",
      "3  GLMPCA  dropout_-1   0.917   0.924   0.929  0.925   0.016   0.031   0.045   \n",
      "4     PCA  dropout_-1   0.957   0.958   0.959  0.961   0.018   0.033   0.048   \n",
      "\n",
      "   aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  COMP  HOMO  \n",
      "0   0.003  ...  0.505  0.529  0.521  0.518  1626  0.00  0.00  0.33  0.00  0.00  \n",
      "1   0.003  ...  0.513  0.534  0.539  0.542   768  0.03  0.04  0.31  0.04  0.04  \n",
      "2   0.010  ...  0.643  0.785  0.767  0.754   349  0.87  0.83  0.46  0.82  0.84  \n",
      "3   0.008  ...  0.638  0.806  0.788  0.777   415  0.76  0.83  0.47  0.82  0.84  \n",
      "4   0.010  ...  0.643  0.790  0.771  0.758   398  0.95  0.93  0.67  0.93  0.93  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.127393\n",
      "1               DREAM  0.191474\n",
      "2                EDGE  0.551769\n",
      "3              GLMPCA  0.618649\n",
      "4                 PCA  0.608145\n",
      "5               PHATE  0.686694\n",
      "6              PaCMAP  0.135641\n",
      "7   ParametricUMAP200  0.747994\n",
      "8    ParametricUMAP50  0.719971\n",
      "9              SAUCIE  0.120387\n",
      "10             SCDRHA  0.421366\n",
      "11              SIMLR  0.734789\n",
      "12               SPDR  0.785808\n",
      "13          SQuaD_MDS  0.460598\n",
      "14   SQuaD_MDS_hybrid  0.684617\n",
      "15             SSNMDI  0.104952\n",
      "16               TSNE  0.718299\n",
      "17             TriMap  0.805976\n",
      "18               UMAP  0.729174\n",
      "19                VAE  0.644032\n",
      "20               ZIFA  0.665825\n",
      "21               ivis  0.505953\n",
      "22               pCMF  0.132585\n",
      "23              scGAE  0.250112\n",
      "24              scGBM  0.622057\n",
      "25            scScope  0.195589\n",
      "26              scvis  0.166644\n",
      "27             tGPLVM  0.323695\n",
      "结果已保存到文件：/home/henu/work/result/score/dropout.csv\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:38:51.949479Z",
     "start_time": "2025-09-16T06:38:51.852297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "DE比例稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['de_prob_0.05','de_prob_0.15','de_prob_0.2','de_prob_0.25','de_prob_0.3']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/de_prob.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "a9514c837b32d963",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method       Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  \\\n",
      "0     DRA  de_prob_0.05   0.241   0.260   0.264  0.288   0.005   0.010   \n",
      "1   DREAM  de_prob_0.05   0.256   0.285   0.289  0.286   0.006   0.011   \n",
      "2    EDGE  de_prob_0.05   0.489   0.508   0.517  0.524   0.008   0.014   \n",
      "3  GLMPCA  de_prob_0.05   0.787   0.799   0.812  0.812   0.009   0.018   \n",
      "4     PCA  de_prob_0.05   0.950   0.952   0.951  0.947   0.010   0.021   \n",
      "\n",
      "   nkr_30  aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  \\\n",
      "0   0.016   0.002  ...  0.504  0.522  0.512  0.510   541 -0.00  0.00  0.32   \n",
      "1   0.015   0.003  ...  0.506  0.519  0.519  0.518   980  0.00  0.00  0.30   \n",
      "2   0.021   0.004  ...  0.524  0.594  0.581  0.572   466  0.12  0.13  0.34   \n",
      "3   0.026   0.005  ...  0.563  0.665  0.665  0.660   580  0.70  0.69  0.42   \n",
      "4   0.030   0.005  ...  0.577  0.680  0.664  0.650   412  0.94  0.91  0.64   \n",
      "\n",
      "   COMP  HOMO  \n",
      "0  0.00  0.00  \n",
      "1  0.00  0.00  \n",
      "2  0.13  0.14  \n",
      "3  0.68  0.70  \n",
      "4  0.91  0.91  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.134130\n",
      "1               DREAM  0.493192\n",
      "2                EDGE  0.695753\n",
      "3              GLMPCA  0.703393\n",
      "4                 PCA  0.718527\n",
      "5               PHATE  0.760284\n",
      "6              PaCMAP  0.144285\n",
      "7   ParametricUMAP200  0.759442\n",
      "8    ParametricUMAP50  0.763334\n",
      "9              SAUCIE  0.120885\n",
      "10             SCDRHA  0.619503\n",
      "11              SIMLR  0.783084\n",
      "12               SPDR  0.795233\n",
      "13          SQuaD_MDS  0.493623\n",
      "14   SQuaD_MDS_hybrid  0.712820\n",
      "15             SSNMDI  0.113809\n",
      "16               TSNE  0.777181\n",
      "17             TriMap  0.812651\n",
      "18               UMAP  0.691654\n",
      "19                VAE  0.755656\n",
      "20               ZIFA  0.713901\n",
      "21               ivis  0.631472\n",
      "22               pCMF  0.102101\n",
      "23              scGAE  0.474859\n",
      "24              scGBM  0.679451\n",
      "25            scScope  0.319310\n",
      "26              scvis  0.137046\n",
      "27             tGPLVM  0.670785\n",
      "结果已保存到文件：/home/henu/work/result/score/de_prob.csv\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:40:04.792038Z",
     "start_time": "2025-09-16T06:40:04.696076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "DE强度稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['de_0.2','de_0.4','de_0.6','de_0.8','de_1.0']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/de_strength.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "fae6bab0d124139d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  de_0.2   0.260   0.264   0.275  0.289   0.006   0.010   0.015   \n",
      "1   DREAM  de_0.2   0.241   0.274   0.285  0.304   0.005   0.010   0.015   \n",
      "2    EDGE  de_0.2   0.341   0.361   0.376  0.386   0.006   0.012   0.017   \n",
      "3  GLMPCA  de_0.2   0.823   0.816   0.826  0.835   0.009   0.017   0.024   \n",
      "4     PCA  de_0.2   0.873   0.874   0.870  0.876   0.008   0.017   0.024   \n",
      "\n",
      "   aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  COMP  HOMO  \n",
      "0   0.003  ...  0.504  0.525  0.508  0.503   531  0.00  0.00  0.33  0.00  0.00  \n",
      "1   0.003  ...  0.505  0.507  0.507  0.507   838  0.00  0.00  0.31  0.00  0.00  \n",
      "2   0.003  ...  0.514  0.608  0.584  0.571   730  0.04  0.04  0.32  0.04  0.04  \n",
      "3   0.005  ...  0.559  0.680  0.661  0.650   471  0.61  0.65  0.38  0.64  0.66  \n",
      "4   0.004  ...  0.558  0.631  0.616  0.607   446  0.65  0.76  0.49  0.75  0.77  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.110793\n",
      "1               DREAM  0.614155\n",
      "2                EDGE  0.677946\n",
      "3              GLMPCA  0.717368\n",
      "4                 PCA  0.749515\n",
      "5               PHATE  0.774999\n",
      "6              PaCMAP  0.131967\n",
      "7   ParametricUMAP200  0.755548\n",
      "8    ParametricUMAP50  0.746988\n",
      "9              SAUCIE  0.131723\n",
      "10             SCDRHA  0.671789\n",
      "11              SIMLR  0.783983\n",
      "12               SPDR  0.812254\n",
      "13          SQuaD_MDS  0.615402\n",
      "14   SQuaD_MDS_hybrid  0.715868\n",
      "15             SSNMDI  0.092834\n",
      "16               TSNE  0.776657\n",
      "17             TriMap  0.823762\n",
      "18               UMAP  0.698623\n",
      "19                VAE  0.776183\n",
      "20               ZIFA  0.751577\n",
      "21               ivis  0.686665\n",
      "22               pCMF  0.298774\n",
      "23              scGAE  0.438460\n",
      "24              scGBM  0.712458\n",
      "25            scScope  0.552512\n",
      "26              scvis  0.440820\n",
      "27             tGPLVM  0.670359\n",
      "结果已保存到文件：/home/henu/work/result/score/de_strength.csv\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:41:18.973565Z",
     "start_time": "2025-09-16T06:41:18.877138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "异常值概率稳定性得分：相关合成数据集的局部/全局/聚类指标的综合\n",
    "'''\n",
    "\n",
    "all_dfs = []\n",
    "datasets = ['out_0.1','out_0.2','out_0.3','out_0.4','out_0.5']\n",
    "for dataset in datasets:\n",
    "    # 局部与全局\n",
    "    datapath1 = f'/home/henu/work/result/metric/simulate/{dataset}/dr1.csv'\n",
    "    datapath2 = f'/home/henu/work/result/metric/simulate/{dataset}/dr2.csv'\n",
    "    # 聚类\n",
    "    datapath3 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_ARI.csv'\n",
    "    datapath4 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_NMI.csv'\n",
    "    datapath5 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_SIL.csv'\n",
    "    datapath6 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_COMP.csv'\n",
    "    datapath7 = f'/home/henu/work/result/cluster/simulate/{dataset}/indicators/kmeans_HOMO.csv'\n",
    "\n",
    "    df1 = pd.read_csv(datapath1)\n",
    "    df2 = pd.read_csv(datapath2)\n",
    "    df3 = pd.read_csv(datapath3)\n",
    "    df4 = pd.read_csv(datapath4)\n",
    "    df5 = pd.read_csv(datapath5)\n",
    "    df6 = pd.read_csv(datapath6)\n",
    "    df7 = pd.read_csv(datapath7)\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, on=\"Method\", how=\"outer\"), [df1, df2, df3, df4, df5, df6, df7])\n",
    "\n",
    "    df_merge.insert(1, \"Dataset\", dataset)  # 加一列标记数据集名\n",
    "    all_dfs.append(df_merge)\n",
    "\n",
    "# 合并所有数据集\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"合并后的数据：\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 提取指标列（除了 Method 和 Dataset）\n",
    "metric_cols = [c for c in df_all.columns if c not in [\"Method\", \"Dataset\",'AUC','Qlocal','Qglobal','kmax']]\n",
    "print(metric_cols)\n",
    "\n",
    "# -------- Step1: 指标标准化（所有方法+数据集一起 min-max）--------\n",
    "scaler = MinMaxScaler()\n",
    "df_all[metric_cols] = scaler.fit_transform(df_all[metric_cols])\n",
    "# print(df_all[['Method']+metric_cols])\n",
    "\n",
    "# -------- Step2: 每个 (方法×数据集) 的指标平均 --------\n",
    "df_all[\"Accuracy_subscore\"] = df_all[metric_cols].mean(axis=1)\n",
    "# print(df_all[['Method','Accuracy_subscore']])\n",
    "\n",
    "# -------- Step3: 跨所有数据集取平均，得到每个方法的最终 Accuracy --------\n",
    "accuracy_scores = df_all.groupby(\"Method\")[\"Accuracy_subscore\"].mean()\n",
    "\n",
    "# 重命名列名为 'score'\n",
    "accuracy_scores = accuracy_scores.rename_axis('Method').reset_index()\n",
    "accuracy_scores.rename(columns={\"Accuracy_subscore\": \"score\"}, inplace=True)\n",
    "\n",
    "print(\"\\n最终 Accuracy 分数：\")\n",
    "print(accuracy_scores)\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"/home/henu/work/result/score/out.csv\"\n",
    "accuracy_scores.to_csv(output_file, index=False)\n",
    "print(f\"结果已保存到文件：{output_file}\")"
   ],
   "id": "c1de513ec9f2fa96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据：\n",
      "   Method  Dataset  knn_10  knn_20  knn_30    svm  nkr_10  nkr_20  nkr_30  \\\n",
      "0     DRA  out_0.1   0.263   0.256   0.259  0.294   0.006   0.011   0.016   \n",
      "1   DREAM  out_0.1   0.280   0.326   0.342  0.364   0.006   0.011   0.016   \n",
      "2    EDGE  out_0.1   0.976   0.973   0.977  0.978   0.021   0.037   0.052   \n",
      "3  GLMPCA  out_0.1   0.925   0.934   0.932  0.938   0.018   0.033   0.048   \n",
      "4     PCA  out_0.1   0.892   0.899   0.900  0.903   0.018   0.033   0.048   \n",
      "\n",
      "   aji_10  ...   T_30   C_10   C_20   C_30  kmax   ARI   NMI   SIL  COMP  HOMO  \n",
      "0   0.003  ...  0.505  0.494  0.496  0.500   250 -0.00  0.00  0.33  0.00  0.00  \n",
      "1   0.003  ...  0.511  0.526  0.526  0.526   938  0.02  0.02  0.31  0.02  0.02  \n",
      "2   0.011  ...  0.656  0.795  0.770  0.756   397  0.94  0.90  0.51  0.89  0.90  \n",
      "3   0.009  ...  0.651  0.829  0.805  0.788   397  0.90  0.87  0.55  0.86  0.87  \n",
      "4   0.009  ...  0.645  0.832  0.806  0.787   396  0.82  0.89  0.71  0.88  0.89  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "['knn_10', 'knn_20', 'knn_30', 'svm', 'nkr_10', 'nkr_20', 'nkr_30', 'aji_10', 'aji_20', 'aji_30', 'random_triplet', 'spearman', 'k-nearest', 'centroid_distance', 'T_10', 'T_20', 'T_30', 'C_10', 'C_20', 'C_30', 'ARI', 'NMI', 'SIL', 'COMP', 'HOMO']\n",
      "\n",
      "最终 Accuracy 分数：\n",
      "               Method     score\n",
      "0                 DRA  0.115898\n",
      "1               DREAM  0.185364\n",
      "2                EDGE  0.766897\n",
      "3              GLMPCA  0.712487\n",
      "4                 PCA  0.731559\n",
      "5               PHATE  0.781317\n",
      "6              PaCMAP  0.131876\n",
      "7   ParametricUMAP200  0.814365\n",
      "8    ParametricUMAP50  0.802486\n",
      "9              SAUCIE  0.108304\n",
      "10             SCDRHA  0.614181\n",
      "11              SIMLR  0.838709\n",
      "12               SPDR  0.821412\n",
      "13          SQuaD_MDS  0.487794\n",
      "14   SQuaD_MDS_hybrid  0.788446\n",
      "15             SSNMDI  0.099864\n",
      "16               TSNE  0.803904\n",
      "17             TriMap  0.844108\n",
      "18               UMAP  0.800950\n",
      "19                VAE  0.773315\n",
      "20               ZIFA  0.724763\n",
      "21               ivis  0.387946\n",
      "22               pCMF  0.086736\n",
      "23              scGAE  0.152563\n",
      "24              scGBM  0.696725\n",
      "25            scScope  0.146762\n",
      "26              scvis  0.084321\n",
      "27             tGPLVM  0.723974\n",
      "结果已保存到文件：/home/henu/work/result/score/out.csv\n"
     ]
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
